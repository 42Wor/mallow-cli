{
  "models": [
    {
      "name": "llama3:8b",
      "huggingFacePath": "meta-llama/Meta-Llama-3-8B-Instruct",
      "description": "Meta's Llama 3 8B Instruct model.",
      "size": "4.7 GB"
    },
    {
      "name": "mistral:7b",
      "huggingFacePath": "mistralai/Mistral-7B-Instruct-v0.2",
      "description": "The 7B instruct model from Mistral AI.",
      "size": "4.1 GB"
    },
    {
      "name": "codegemma:2b",
      "huggingFacePath": "google/codegemma-2b",
      "description": "Google's 2B model for code generation.",
      "size": "1.6 GB"
    },
    {
      "name": "phi-3:mini",
      "huggingFacePath": "microsoft/Phi-3-mini-4k-instruct",
      "description": "Microsoft's powerful 3.8B 'mini' model.",
      "size": "2.2 GB"
    },
    {
      "name": "tinystories:33m",
      "huggingFacePath": "roneneldan/TinyStories-33M",
      "description": "A tiny 33M parameter model for fast testing.",
      "size": "132 MB"
    },
    {
      "name": "mixtral:8x7b",
      "huggingFacePath": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "description": "Mistral's powerful Mixture-of-Experts model.",
      "size": "26 GB"
    },
    {
      "name": "llava:7b",
      "huggingFacePath": "llava-hf/llava-1.5-7b-hf",
      "description": "A multimodal model for vision and language.",
      "size": "~7.5 GB"
    },
    {
      "name": "nomic-embed-text",
      "huggingFacePath": "nomic-ai/nomic-embed-text-v1.5",
      "description": "State-of-the-art text embedding model.",
      "size": "275 MB"
    }
  ]
}